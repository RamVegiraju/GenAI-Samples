{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bebdba0-895a-4d08-b3dc-1f8831f72d7e",
   "metadata": {},
   "source": [
    "## Amazon Bedrock Introduction\n",
    "\n",
    "Reference: https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/00_Intro/bedrock_boto3_setup.ipynb\n",
    "\n",
    "Setting: conda_python3 kernel, ml.c5.xlarge instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52607d33-2f6c-4421-8661-9f3ce509e3ea",
   "metadata": {},
   "source": [
    "We want the latest version of boto3 and langchain that includes Bedrock, note this may change as the packages update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c26cc5-6e2d-478d-ae29-b6a4a1cf2df4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\" \\\n",
    "    \"langchain>0.0.306\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86cc478-8d31-4c94-b4bf-ab0f17c6e403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495d3704-a68b-4080-8f9a-eaa7c3456833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('bedrock')\n",
    "runtime = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d594955d-c0fd-4073-8e49-4fabf155843a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_map = client.list_foundation_models()['modelSummaries']\n",
    "for model in model_map:\n",
    "    print(model['modelName'])\n",
    "    print(model['modelId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891ea059-bd63-4f35-ad4d-acf2aa4b92b3",
   "metadata": {},
   "source": [
    "### Sample Inference Utilizing Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8003125e-8541-456f-9927-346b04a5e432",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "model_id = 'anthropic.claude-v2'\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "prompt_data = \"\"\"Human: Write me a small paragraph saying nice things about me.\n",
    "\n",
    "Assistant:\n",
    "\"\"\"\n",
    "\n",
    "body = json.dumps({\"prompt\": prompt_data, \"max_tokens_to_sample\": 500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65872e76-e0b0-477f-a4b1-80d67355a392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = runtime.invoke_model(\n",
    "    body=body, modelId=model_id, accept=accept, contentType=contentType\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fb983e-38c1-4493-a1db-ef084d8df1df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_body = json.loads(response.get(\"body\").read())\n",
    "print(response_body.get(\"completion\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e62a43-18b9-41ae-8568-a28d470291bc",
   "metadata": {},
   "source": [
    "#### Streaming Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e241f00-5027-410b-a9e2-ca6776dea3d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, display, display_markdown, Markdown\n",
    "\n",
    "response = runtime.invoke_model_with_response_stream(\n",
    "    body=body, modelId=model_id, accept=accept, contentType=contentType\n",
    ")\n",
    "stream = response.get('body')\n",
    "output = []\n",
    "\n",
    "if stream:\n",
    "    for event in stream:\n",
    "        chunk = event.get('chunk')\n",
    "        if chunk:\n",
    "            chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "            text = chunk_obj['completion']\n",
    "            clear_output(wait=True)\n",
    "            output.append(text)\n",
    "            display_markdown(Markdown(''.join(output)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d3326d-fa64-4405-852e-a863ddfbf393",
   "metadata": {},
   "source": [
    "### LangChain Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481911f2-6be5-42af-a282-a367f8a811ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_params = {\"max_tokens_to_sample\": 500,\n",
    "                \"top_k\": 100,\n",
    "                \"top_p\": .95,\n",
    "                \"temperature\": .5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b7b90b-17d6-4000-b4b0-b07f8a56c0f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import Bedrock\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm = Bedrock(\n",
    "    model_id=model_id,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    model_kwargs=model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2c7135-f9b8-4182-a238-aacab93a1e51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm(\"Give me a recipe for pizza please.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
