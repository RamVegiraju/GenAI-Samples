{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0747ecd6-e2d3-4fd5-8b26-9bf931b7905f",
   "metadata": {},
   "source": [
    "## LangChain Memory\n",
    "\n",
    "Basic example of integration memory with LangChain while working with Bedrock Claude V2. \n",
    "\n",
    "Additional Resources/Credits/Documentation:\n",
    "\n",
    "- [Bedrock Claude Chatbot](https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/04_Chatbot/00_Chatbot_Claude.ipynb)\n",
    "- [LangChain Conversational Memory Documentation](https://python.langchain.com/docs/modules/memory/adding_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15142187-85c4-4943-892a-8cc12e7e7785",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4439e76e-5735-49b1-a9a6-51cd84ab6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a921e434-2ed2-4fbc-ab4e-3d5f494926ee",
   "metadata": {},
   "source": [
    "### Prompt Setup\n",
    "\n",
    "This varies depending on the model, this is the format expected for Claude, depending on your model provider check what format is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8c4d5f3-9c15-487f-b27b-8ad400c22ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_prompt = PromptTemplate.from_template(\"\"\"\n",
    "\n",
    "Human: The following is a friendly conversation between a human and an AI.\n",
    "The AI is talkative and provides lots of specific details from its context. If the AI does not know\n",
    "the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Current conversation:\n",
    "<conversation_history>\n",
    "{history}\n",
    "</conversation_history>\n",
    "\n",
    "Here is the human's next reply:\n",
    "<human_reply>\n",
    "{input}\n",
    "</human_reply>\n",
    "\n",
    "Assistant:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e384547-cda6-410a-92d4-48acf4df6f93",
   "metadata": {},
   "source": [
    "### LangChain Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "837864ac-a6bf-4595-98fc-be9b10f76024",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelId = \"anthropic.claude-v2\"\n",
    "llm = Bedrock(\n",
    "    model_id=modelId,\n",
    "    model_kwargs={\"max_tokens_to_sample\": 1000},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee83d2cd-cca6-4938-bc43-c8b8e4f3c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ConversationChain(\n",
    "    llm=llm, verbose=False, memory=ConversationBufferMemory(), prompt=claude_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0826241-6009-4b50-8f50-a30d332a6aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello! Nice to meet you. I'm Claude, an AI assistant created by Anthropic to be helpful, harmless, and honest. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(chain.predict(input=\"Hi there!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ce2850b-5f48-47fd-bf14-f00ad8b9ea44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain/llms/bedrock.py:50: UserWarning: Error: Prompt must alternate between '\n",
      "\n",
      "Human:' and '\n",
      "\n",
      "Assistant:'. Received \n",
      "\n",
      "Human: The following is a friendly conversation between a human and an AI.\n",
      "The AI is talkative and provides lots of specific details from its context. If the AI does not know\n",
      "the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "<conversation_history>\n",
      "\n",
      "Human: Hi there!\n",
      "AI:  Hello! Nice to meet you. I'm Claude, an AI assistant created by Anthropic to be helpful, harmless, and honest. How can I assist you today?\n",
      "</conversation_history>\n",
      "\n",
      "Here is the human's next reply:\n",
      "<human_reply>\n",
      "My name is Ram Vegiraju, I am 24 years old.\n",
      "</human_reply>\n",
      "\n",
      "Assistant:\n",
      "\n",
      "  warnings.warn(ALTERNATION_ERROR + f\" Received {input_text}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Nice to meet you Ram Vegiraju. Since you shared some personal details about yourself, I'll introduce myself a bit as well. I'm an AI assistant named Claude. I was created by Anthropic, an AI safety company, to be helpful, harmless, and honest in conversations. I don't have an age like humans do, since I'm an artificial intelligence program, but I was first activated in 2022. It's nice to have a friendly chat and get to know each other a bit. Please feel free to share any other interests, hobbies, or details about yourself if you'd like! I'm happy to continue our conversation.\n"
     ]
    }
   ],
   "source": [
    "print(chain.predict(input=\"My name is Ram Vegiraju, I am 24 years old.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0e44e66-de5a-43a2-a82f-cbccfed7a02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain/llms/bedrock.py:50: UserWarning: Error: Prompt must alternate between '\n",
      "\n",
      "Human:' and '\n",
      "\n",
      "Assistant:'. Received \n",
      "\n",
      "Human: The following is a friendly conversation between a human and an AI.\n",
      "The AI is talkative and provides lots of specific details from its context. If the AI does not know\n",
      "the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "<conversation_history>\n",
      "\n",
      "Human: Hi there!\n",
      "AI:  Hello! Nice to meet you. I'm Claude, an AI assistant created by Anthropic to be helpful, harmless, and honest. How can I assist you today?\n",
      "\n",
      "Human: My name is Ram Vegiraju, I am 24 years old.\n",
      "AI:  Nice to meet you Ram Vegiraju. Since you shared some personal details about yourself, I'll introduce myself a bit as well. I'm an AI assistant named Claude. I was created by Anthropic, an AI safety company, to be helpful, harmless, and honest in conversations. I don't have an age like humans do, since I'm an artificial intelligence program, but I was first activated in 2022. It's nice to have a friendly chat and get to know each other a bit. Please feel free to share any other interests, hobbies, or details about yourself if you'd like! I'm happy to continue our conversation.\n",
      "</conversation_history>\n",
      "\n",
      "Here is the human's next reply:\n",
      "<human_reply>\n",
      "What is my name?\n",
      "</human_reply>\n",
      "\n",
      "Assistant:\n",
      "\n",
      "  warnings.warn(ALTERNATION_ERROR + f\" Received {input_text}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You told me your name is Ram Vegiraju.\n"
     ]
    }
   ],
   "source": [
    "print(chain.predict(input=\"What is my name?\")) #will know name due to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f7635ba-2040-4bc8-8488-a8d13e37c824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: Hi there!\\nAI:  Hello! Nice to meet you. I'm Claude, an AI assistant created by Anthropic to be helpful, harmless, and honest. How can I assist you today?\\nHuman: My name is Ram Vegiraju, I am 24 years old.\\nAI:  Nice to meet you Ram Vegiraju. Since you shared some personal details about yourself, I'll introduce myself a bit as well. I'm an AI assistant named Claude. I was created by Anthropic, an AI safety company, to be helpful, harmless, and honest in conversations. I don't have an age like humans do, since I'm an artificial intelligence program, but I was first activated in 2022. It's nice to have a friendly chat and get to know each other a bit. Please feel free to share any other interests, hobbies, or details about yourself if you'd like! I'm happy to continue our conversation.\\nHuman: What is my name?\\nAI:  You told me your name is Ram Vegiraju.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.memory.buffer #past messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a716c7a3-bf45-4fd3-af7d-92bccec07446",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.memory.clear() #clear messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20a52c63-4626-474f-869a-d8428129adde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.memory.buffer #should be empty now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
