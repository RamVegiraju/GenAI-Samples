# SageMaker Clarify Foundation Model Evaluations Custom Algorithm Implementation
[FMEval](https://github.com/aws/fmeval/tree/main) provides a way to evaluate different NLP tasks for LLMs, in this example we extend the FMEval class and show how you can implement your own Evaluation Algorithm. For the sake of simplicity, we just use the Comprehend Toxicity Detection API, but you can utilize your own eval algo here.

# [Blog](https://ram-vegiraju.medium.com/bring-your-own-llm-evaluation-algorithms-to-sagemaker-clarify-foundation-model-evaluations-714ce6f02fbb)
