{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba7f05a-8d23-4ee6-8c26-a3b11808fcbb",
   "metadata": {},
   "source": [
    "# SageMaker JumpStart LLM Deployment Introduction\n",
    "SageMaker JumpStart allows for you to easily train, deploy, and evaluate LLMs without having to worry about Model Serving/Containerization or selecting optimal hardware to back the endpoint. In this example we quickly introduce how you can deploy a Llama3-8B Text Generation model using the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) to interact with JumpStart easily.\n",
    "\n",
    "## Credits/ References\n",
    "For original JumpStart samples/examples refer to this repository and the Llama3-8B text completion sample: https://github.com/aws/amazon-sagemaker-examples/tree/default/%20%20%20%20generative_ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddb5516-24f1-4918-85d7-93bf3c43852d",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We install the SageMaker Python SDK to work with JumpStart in a simplified manner, this abstracts out lower level API calls you might need to make with Boto3 the AWS Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d707b564-0bb1-4044-a0c9-696f71d51a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6428518-a4d9-4406-b685-ee870b72da1d",
   "metadata": {},
   "source": [
    "## Llama3-8B JumpStart Deployment & Sample Inference\n",
    "To work with Llama3-8B we specify the Model ID, which can be found on the Model Cards in the JumpStart landing page or do this programatically with the following snippet:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922ab9c2-fad2-4f83-a657-dd02c2838815",
   "metadata": {},
   "source": [
    "### List Available Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb2b092-5a24-4ea8-bb82-be32b6e09557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.jumpstart.notebook_utils import list_jumpstart_models\n",
    "\n",
    "# return all models and filter for model family of your choice\n",
    "models = list_jumpstart_models()\n",
    "model_family = 'llama-3'\n",
    "\n",
    "# Display llama3 based models\n",
    "for model in models:\n",
    "    if model_family in model:\n",
    "        print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a98eccd-4024-44f8-983d-bf5a6778bd81",
   "metadata": {},
   "source": [
    "### Deploy Model\n",
    "Ensure to request a Service Quota Limit increase if needed, for Llama3-8B you need a ml.g5.12xlarge for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bdf954-de05-4f54-b0dd-2eeb85fb6f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "model = JumpStartModel(model_id = \"meta-textgeneration-llama-3-8b\")\n",
    "predictor = model.deploy(accept_eula=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2164a1-711d-469f-97fc-1b50b5757d16",
   "metadata": {},
   "source": [
    "### Sample Inference\n",
    "Ensure to structure the payload in the format that the model provider expects, this varies model to model so check the samples repo and model card to understand this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f15ee-c6de-4851-9bd3-9a79ce53472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user input\n",
    "query = \"What is AWS?\"\n",
    "\n",
    "# payload structuring for Llama expected format\n",
    "payload = {\n",
    "    \"inputs\": query,\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 64,\n",
    "        \"top_p\": 0.9,\n",
    "        \"temperature\": 0.6,\n",
    "        \"return_full_text\": False,\n",
    "    },\n",
    "}\n",
    "print(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb742a-746b-4af7-ab8b-2f130c14262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample model inference\n",
    "response = predictor.predict(payload, custom_attributes=\"accept_eula=true\")\n",
    "print(response['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fa9456-5b2b-4436-bc6c-ed93d313c98d",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "Ensure to delete your SageMaker endpoint to not incur further costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6861d32c-bf2b-4af7-baf3-95da5df2108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletes SageMaker endpoint\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
